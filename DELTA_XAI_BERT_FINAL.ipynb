{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tommy-Adisa/Explainable-Suicide-Risk-Detection-with-Transformers/blob/main/DELTA_XAI_BERT_FINAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNpl1YxjMuX4"
      },
      "outputs": [],
      "source": [
        "!pip install transformers torch torchvision torchaudio scikit-learn pandas numpy tqdm contractions captum wordcloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4XHjdxZVKxv"
      },
      "outputs": [],
      "source": [
        "#!pip install wordcloud\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MVHt8h2O1Mo"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import nltk\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "BASE_DIR = \"/content/drive/My Drive/Colab Notebooks/explainable_suicide_detection/bert_explainability_outputs\"\n",
        "os.makedirs(BASE_DIR, exist_ok=True)\n",
        "\n",
        "print(\"Saving outputs to:\", BASE_DIR)\n"
      ],
      "metadata": {
        "id": "kq3sWf6vptrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtmjP-HBNWv-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import (\n",
        "BertTokenizer,\n",
        "BertForSequenceClassification,\n",
        "Trainer,\n",
        "TrainingArguments\n",
        ")\n",
        "from captum.attr import IntegratedGradients\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8k6e0YM9Aeg"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "#df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/explainable_suicide_detection/data/raw/Suicide_Detection.csv')\n",
        "#df.head()\n",
        "\n",
        "#print(df['class'].value_counts())\n",
        "#print(len(df))\n",
        "\n",
        "# Load dataset\n",
        "df_all = pd.read_csv('/content/drive/My Drive/Colab Notebooks/explainable_suicide_detection/data/raw/Suicide_Detection.csv')\n",
        "df_all.head()\n",
        "\n",
        "print(df_all['class'].value_counts())\n",
        "print(len(df_all))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Mp47fVq8DdX"
      },
      "source": [
        "#NOTE SECTION BELLOW"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9qM40ec72gC"
      },
      "source": [
        "#WE NEED TO DOWNSAMPLE THE DATASET TO HELP FOR THE CODING. AFTER ALL IS DONE, THEN WE WILL REMOVE THIS SECTION TO RUN IT ON ALL THE CODE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T963Ei7v8UVP"
      },
      "outputs": [],
      "source": [
        "\n",
        "df_all = df_all.drop_duplicates(subset='text')\n",
        "\n",
        "N = 7000\n",
        "df = df_all.groupby('class').apply(lambda x: x.sample(N, random_state=42)).reset_index(drop=True)\n",
        "\n",
        "df.to_csv(\"/content/drive/My Drive/Colab Notebooks/explainable_suicide_detection/data/reduced/suicide_data_small.csv\", index=False)\n",
        "\n",
        "print(df['class'].value_counts())\n",
        "print(len(df))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENAeC_T9NsgY"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Confirm dataset structure\n",
        "print(df.columns)\n",
        "print(df['class'].value_counts())\n",
        "print(df.shape)\n",
        "list(df.columns)\n",
        "\n",
        "df = df[[\"text\", \"class\"]]\n",
        "label_map = {\"non-suicide\": 0, \"suicide\": 1}\n",
        "df[\"label\"] = df[\"class\"].map(label_map)\n",
        "\n",
        "#PRINT FIRTH 10\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5KEj41YR9Ux"
      },
      "source": [
        "###THIS IS TO SPLIT THE DATASET BEFORE CLEANING."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFlZV5oYSMl1"
      },
      "source": [
        "“Minimal text preprocessing was applied to preserve linguistic and emotional cues essential for transformer-based models. Unlike traditional machine learning pipelines, aggressive text normalisation was avoided to ensure meaningful attention distributions and faithful Integrated Gradient attributions.”\n",
        "\n",
        "When we clean before spliting, we let  information from test data influence training data\n",
        "\n",
        "Cleaning before splitting, cause risk of:\n",
        "\n",
        "Vocabulary leakage, Distribution leakage, Over-optimistic performance, Invalid explainability results\n",
        "\n",
        "BERT was trained on raw, messy, natural language, including:\n",
        "\n",
        "punctuation, repetition, emotional intensity, informal text, subwords, casing (for cased models). IF we remove too much hurts performance and explainability. Therfore, for safe cleaning and minimal cleaning, we will perform: Lowercasing,Removing URLs\n",
        "\n",
        "Removing HTML tags\n",
        "\n",
        "Expanding contractions\n",
        "\n",
        "Removing emojis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQH7qgy0bgk9"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import contractions\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwInzQaEbj7A"
      },
      "source": [
        "###Clean functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpWiEn7Oh4tc"
      },
      "outputs": [],
      "source": [
        "def clean_contractions(text):\n",
        "    try:\n",
        "        return contractions.fix(text)\n",
        "    except:\n",
        "        return text  # fallback if contractions fails\n",
        "\n",
        "def remove_html_tags_func(text):\n",
        "    return re.sub(r'<.*?>', '', text)\n",
        "\n",
        "def remove_url_func(text):\n",
        "    return re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
        "\n",
        "def remove_emoji(text):\n",
        "    emoji_pattern = re.compile(\n",
        "        \"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"\n",
        "        u\"\\U0001F300-\\U0001F5FF\"\n",
        "        u\"\\U0001F680-\\U0001F6FF\"\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"\n",
        "        u\"\\U00002500-\\U00002BEF\"\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U0001F900-\\U0001F9FF\"\n",
        "        u\"\\U0001FA70-\\U0001FAFF\"\n",
        "        u\"\\U0001F018-\\U0001F270\"\n",
        "        u\"\\U0001F650-\\U0001F67F\"\n",
        "        \"]+\",\n",
        "        flags=re.UNICODE,\n",
        "    )\n",
        "    return emoji_pattern.sub(r\"\", text)\n",
        "\n",
        "def clean_text_bert(text):\n",
        "    text = str(text) if text else \"\"\n",
        "    text = text.strip()\n",
        "    if text == \"\":\n",
        "        return \"\"\n",
        "    text = clean_contractions(text)\n",
        "    text = remove_html_tags_func(text)\n",
        "    text = remove_url_func(text)\n",
        "    text = remove_emoji(text)\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ8XMMLhb0uB"
      },
      "source": [
        "###Stratified Train-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMy9OpVeVZ6L"
      },
      "outputs": [],
      "source": [
        "train_df, val_df = train_test_split(\n",
        "    df.copy(),\n",
        "    test_size=0.2,\n",
        "    stratify=df['label'],\n",
        "    random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bO1351giJGp"
      },
      "source": [
        "####Fill NaN & ensure strings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wn7U-6WUfr9E"
      },
      "outputs": [],
      "source": [
        "train_df['text'] = train_df['text'].fillna(\"\").astype(str)\n",
        "val_df['text']   = val_df['text'].fillna(\"\").astype(str)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTNhEAvmb_z_"
      },
      "source": [
        "####Apply Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2fABk05dFwF"
      },
      "outputs": [],
      "source": [
        "train_df['clean_text'] = train_df['text'].apply(clean_text_bert)\n",
        "val_df['clean_text']   = val_df['text'].apply(clean_text_bert)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHZT_iCmi9n2"
      },
      "outputs": [],
      "source": [
        "# Sample 5 random rows from each class\n",
        "sample_class_1 = train_df[train_df['label'] == 1].sample(5, random_state=42)\n",
        "sample_class_0 = train_df[train_df['label'] == 0].sample(5, random_state=42)\n",
        "\n",
        "# Combine them and reset index\n",
        "sample_train_df = pd.concat([sample_class_1, sample_class_0]).reset_index(drop=True)\n",
        "\n",
        "# Display only the columns you want, like with head()\n",
        "sample_train_df[[ 'text', 'clean_text', 'class', 'label']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fiefe1g5kevf"
      },
      "source": [
        "###Extract lists for tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qS4CLEwnkbVM"
      },
      "outputs": [],
      "source": [
        "train_texts  = train_df['clean_text'].tolist()\n",
        "train_labels = train_df['label'].tolist()\n",
        "\n",
        "val_texts    = val_df['clean_text'].tolist()\n",
        "val_labels   = val_df['label'].tolist()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwHJnZ9alKrB"
      },
      "source": [
        "###Tokenize with Hugging Face BertTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNdvM-3MlQuh"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=128)\n",
        "val_encodings   = tokenizer(val_texts, truncation=True, padding=True, max_length=128)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tp39-ixrrZ3_"
      },
      "source": [
        "###Dataset Wrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y35MwI-XsKfL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTWdL9bgxVsI"
      },
      "source": [
        "####This is to Define batch size and device. We will use the approach of effective batch size batch_size = 8, gradient_accumulation_steps = 2, Effective batch size = 8 * 2 = 16. The optimizer will only update weights after accumulating gradients over 2 batches, effectively mimicking a batch of 16."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Heo8tMKsxWn0"
      },
      "outputs": [],
      "source": [
        "batch_size = 8\n",
        "gradient_accumulation_steps = 2\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2brugxXrrZbs"
      },
      "outputs": [],
      "source": [
        "class TokenizedDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pn_78h7Csl1c"
      },
      "source": [
        "##Prepare Tokenizers and datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsy8IdRxssFq"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Create Dataset objects\n",
        "train_dataset = TokenizedDataset(train_encodings, train_labels)\n",
        "val_dataset   = TokenizedDataset(val_encodings, val_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B45wLWosvTlk"
      },
      "source": [
        "###This is to Wrap into DataLoader for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tzxmf5DsvV-e"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccgVdiELywKi"
      },
      "outputs": [],
      "source": [
        "batch = next(iter(train_loader))\n",
        "print(\"input_ids:\", batch['input_ids'].shape)        # [batch_size, max_len]\n",
        "print(\"attention_mask:\", batch['attention_mask'].shape)\n",
        "print(\"labels:\", batch['labels'].shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yi-g3Vj7y9Ij"
      },
      "source": [
        "###Difine model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZiLPbGB2nYl"
      },
      "outputs": [],
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "num_labels = 2  # binary classification\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels=num_labels ,\n",
        "    output_attentions=True\n",
        ")\n",
        "\n",
        "model.to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAtDDHH-22GK"
      },
      "source": [
        "####This is to difine the optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7z8Yo83271R"
      },
      "outputs": [],
      "source": [
        "from torch.optim import AdamW\n",
        "\n",
        "\n",
        "optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr=2e-5,          # standard for BERT\n",
        "    eps=1e-8\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kp1W4nxb4BsK"
      },
      "outputs": [],
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs = 3\n",
        "total_steps = len(train_loader) * epochs // gradient_accumulation_steps\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=int(0.1 * total_steps),\n",
        "    num_training_steps=total_steps\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZjCsNropBcM"
      },
      "outputs": [],
      "source": [
        "print(next(model.parameters()).device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJQTRtLR0agW"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "epochs = 3\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    loop = tqdm(\n",
        "        enumerate(train_loader),\n",
        "        total=len(train_loader),\n",
        "        desc=f\"Epoch {epoch+1}\",\n",
        "        leave=True\n",
        "    )\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    for step, batch in loop:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels\n",
        "        )\n",
        "\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss = loss / gradient_accumulation_steps\n",
        "        loss.backward()\n",
        "\n",
        "        if (step + 1) % gradient_accumulation_steps == 0:\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        #  tqdm live update\n",
        "        loop.set_postfix(loss=f\"{loss.item():.4f}\")\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch+1} finished. Average loss: {avg_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKgjsoMPCvVw"
      },
      "source": [
        "#EVALUATION OF BERT#\n",
        "##1. Confusion matrix 2. Precision, recall, F1 3. Classification report 4. Store correctly predicted suicide samples 5. Store correctly predicted non-suicide samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gByn3FVb09pc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    classification_report,\n",
        "    precision_recall_fscore_support\n",
        ")\n",
        "\n",
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDSIRQZqDPOY"
      },
      "outputs": [],
      "source": [
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "correct_suicide_samples = []\n",
        "correct_nonsuicide_samples = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(val_loader, desc=\"Evaluating\", leave=True):\n",
        "\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )\n",
        "\n",
        "        logits = outputs.logits\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        # Store correctly predicted samples\n",
        "        for i in range(len(labels)):\n",
        "            if preds[i] == labels[i]:\n",
        "                if labels[i].item() == 1:\n",
        "                    correct_suicide_samples.append(input_ids[i].cpu())\n",
        "                else:\n",
        "                    correct_nonsuicide_samples.append(input_ids[i].cpu())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xkh3o1bIEq86"
      },
      "source": [
        "##CONFUSION MATRIX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sw4JVDI7EWkW"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Non-Suicide', 'Suicide'],\n",
        "            yticklabels=['Non-Suicide', 'Suicide'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('BERT Confusion Matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhBIw6iPE1Bz"
      },
      "source": [
        "#Precision, Recall, F1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lK2HegZQEpV1"
      },
      "outputs": [],
      "source": [
        "precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "    all_labels,\n",
        "    all_preds,\n",
        "    average='binary'\n",
        ")\n",
        "\n",
        "print(f\"BERT_Precision: {precision:.4f}\")\n",
        "print(f\"BERT_Recall:    {recall:.4f}\")\n",
        "print(f\"BERT_F1-score:  {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jd_iTCLlFLy2"
      },
      "outputs": [],
      "source": [
        "print(\n",
        "    classification_report(\n",
        "        all_labels,\n",
        "        all_preds,\n",
        "        target_names=['Non-Suicide', 'Suicide']\n",
        "    )\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ntR8CbjFbp-"
      },
      "outputs": [],
      "source": [
        "def decode_samples(token_ids, tokenizer, max_samples=50):\n",
        "    texts = []\n",
        "    for ids in token_ids[:max_samples]:\n",
        "        text = tokenizer.decode(ids, skip_special_tokens=True)\n",
        "        texts.append(text)\n",
        "    return texts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUHzgGjZFf9q"
      },
      "outputs": [],
      "source": [
        "correct_suicide_texts = decode_samples(\n",
        "    correct_suicide_samples,\n",
        "    tokenizer\n",
        ")\n",
        "\n",
        "correct_nonsuicide_texts = decode_samples(\n",
        "    correct_nonsuicide_samples,\n",
        "    tokenizer\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWGeMF2wFli9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.DataFrame({'text': correct_suicide_texts}).to_csv(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/explainable_suicide_detection/correct_suicide_samples.csv\", index=False\n",
        ")\n",
        "\n",
        "pd.DataFrame({'text': correct_nonsuicide_texts}).to_csv(\n",
        "    '/content/drive/My Drive/Colab Notebooks/explainable_suicide_detection/correct_nonsuicide_samples.csv', index=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4L55-KWHxT7"
      },
      "source": [
        "#EXPLAINABILITY AI ATTENTION + INTEGRATED GRADIENT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGNxxHghIT4G"
      },
      "source": [
        "#NOTE\n",
        "\n",
        "### What attention shows\n",
        "##Attention answers: “Which words did BERT focus on when forming its internal representation?”\n",
        "In practice:\n",
        "•\tAttention scores show token-to-token influence\n",
        "•\tThey highlight contextual importance\n",
        "•\tThey are model-internal signals, not causal proofs\n",
        "\n",
        "###Important limitation\n",
        "##Attention ≠ Explanation by itself\n",
        "This is a known research conclusion:\n",
        "•\tHigh attention ≠ high importance\n",
        "\n",
        "##Attention shows where the model looks, not why the output changes\n",
        " So attention alone is insufficient for explainability\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPVi6MzwI0OJ"
      },
      "source": [
        "##TASK TO DO NEXT\n",
        "####combine attention mechanisms and Integrated Gradients to identify both model focus and causal word-level contributions, highlighting their alignment and divergence”"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHMOpIP5PDjb"
      },
      "source": [
        "###Select sample from sucide"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93KmU8SzPKU1"
      },
      "source": [
        "####Tokinize the sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqnhD5PbOi5c"
      },
      "outputs": [],
      "source": [
        "#pick a sample\n",
        "sample_text = correct_suicide_texts[8]\n",
        "\n",
        "inputs = tokenizer(\n",
        "    sample_text,\n",
        "    return_tensors='pt',\n",
        "    truncation=True,\n",
        "    max_length=128\n",
        ").to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fzha6grxPdGY"
      },
      "source": [
        "###Forward pass with attention extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jugoLx7jPcTo"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "attentions = outputs.attentions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YluNT7rAPoJ3"
      },
      "source": [
        "###Aggregate attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BzDiPTyPryn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Average heads first → shape: (layers, tokens, tokens)\n",
        "layer_attentions = torch.stack([layer.mean(dim=1).squeeze(0) for layer in attentions])\n",
        "\n",
        "# Average across layers → overall attention\n",
        "avg_attention = layer_attentions.mean(dim=0)  # shape: (tokens, tokens)\n",
        "\n",
        "# CLS token attention to all tokens\n",
        "cls_attention = avg_attention[0]  # shape: (tokens,)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhRciyLjaxNo"
      },
      "source": [
        "####Merge WordPiece tokens into words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCAGWgmvayqp"
      },
      "outputs": [],
      "source": [
        "def merge_wordpieces(tokens, attention_scores):\n",
        "    words = []\n",
        "    word_scores = []\n",
        "\n",
        "    current_word = ''\n",
        "    current_score = 0.0\n",
        "    count = 0\n",
        "\n",
        "    for token, score in zip(tokens, attention_scores):\n",
        "        if token.startswith('##'):\n",
        "            current_word += token[2:]\n",
        "            current_score += score\n",
        "            count += 1\n",
        "        else:\n",
        "            if current_word != '':\n",
        "                words.append(current_word)\n",
        "                word_scores.append(current_score / count)\n",
        "            current_word = token\n",
        "            current_score = score\n",
        "            count = 1\n",
        "\n",
        "    # Append last word\n",
        "    words.append(current_word)\n",
        "    word_scores.append(current_score / count)\n",
        "\n",
        "    return words, torch.tensor(word_scores)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHsfxkwHa5wF"
      },
      "outputs": [],
      "source": [
        "tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
        "words, word_attention = merge_wordpieces(tokens, cls_attention.cpu())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ox6kaE9GVEww"
      },
      "source": [
        "###Heatmap of attention across tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORvKK3KOXCR6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "top_k = 15\n",
        "top_indices = np.argsort(word_attention.numpy())[::-1][:top_k]\n",
        "top_words = [words[i] for i in top_indices]\n",
        "\n",
        "# Fix negative-stride issue\n",
        "word_attention_np = word_attention.numpy()\n",
        "top_values = word_attention_np[top_indices]\n",
        "\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.bar(top_words, top_values, color='salmon')\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylabel(\"Attention Weight\")\n",
        "plt.title(\"Top-K Words by CLS Attention\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZiYAhSnEbmpX"
      },
      "outputs": [],
      "source": [
        "word_attention_np = word_attention.numpy()\n",
        "top_values = word_attention_np[top_indices]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLuRt6PebGof"
      },
      "outputs": [],
      "source": [
        "from matplotlib import cm\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "def highlight_text(words, attention_scores):\n",
        "    # Normalize\n",
        "    scores = (attention_scores - attention_scores.min()) / (attention_scores.max() - attention_scores.min())\n",
        "    cmap = cm.get_cmap('Reds')\n",
        "    html = ''\n",
        "    for word, score in zip(words, scores):\n",
        "        color = cm.colors.to_hex(cmap(score))\n",
        "        html += f'<span style=\"background-color:{color}\">{word} </span>'\n",
        "    return html\n",
        "\n",
        "html = highlight_text(words, word_attention)\n",
        "display(HTML(html))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aeo4AsxZXpd0"
      },
      "outputs": [],
      "source": [
        "cls_numpy = cls_attention.cpu().numpy()\n",
        "top_values = cls_numpy[top_indices]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYpndqmlVGEr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "top_k = 15\n",
        "\n",
        "# Convert to NumPy and fix negative-stride issues\n",
        "word_attention_np = word_attention.numpy()\n",
        "\n",
        "# Get top-K indices\n",
        "top_indices = np.argsort(word_attention_np)[::-1][:top_k]\n",
        "\n",
        "# Get top-K words and their attention scores\n",
        "top_words = [words[i] for i in top_indices]\n",
        "top_values = word_attention_np[top_indices]\n",
        "\n",
        "# Plot like the first style (line plot with markers)\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.plot(top_values, marker='o', linestyle='-', color='royalblue')\n",
        "plt.xticks(range(top_k), top_words, rotation=45)\n",
        "plt.ylabel(\"Attention Weight\")\n",
        "plt.title(f\"Top-{top_k} Words by CLS Attention\")\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GaKWsispVWwY"
      },
      "outputs": [],
      "source": [
        "token_importance = list(zip(tokens, cls_attention.cpu().numpy()))\n",
        "\n",
        "# Sort by importance\n",
        "token_importance = sorted(token_importance, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "for token, score in token_importance[:10]:\n",
        "    print(f\"{token}: {score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UuznGHS3VpRt"
      },
      "outputs": [],
      "source": [
        "combined_attention = torch.zeros_like(attentions[0][0][0])\n",
        "\n",
        "for layer in attentions:\n",
        "    for head in layer[0]:\n",
        "        combined_attention += head\n",
        "\n",
        "combined_attention /= (len(attentions) * layer.shape[1])\n",
        "\n",
        "cls_combined = combined_attention[0]\n",
        "cls_combined /= cls_combined.sum()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPgpg6lsxzRd"
      },
      "outputs": [],
      "source": [
        "layer = -1\n",
        "head = 3\n",
        "\n",
        "head_attention = attentions[layer][0, head, 0].detach().cpu().numpy()\n",
        "\n",
        "plt.figure(figsize=(12,3))\n",
        "plt.plot(head_attention)\n",
        "plt.xticks(range(len(tokens)), tokens, rotation=90)\n",
        "plt.title(f\"Layer {layer}, Head {head} CLS Attention\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIB5u9FRzxzP"
      },
      "source": [
        "###“Attention visualisation showed dominant focus on special tokens ([CLS], [SEP]) with diffuse distribution across content words. This supports prior findings that attention weights do not reliably correspond to feature importance. Therefore, Integrated Gradients were employed for faithful attribution.”"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TL0kmht20Y7j"
      },
      "source": [
        "#INTEGRATED GRADIENTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57KgqJcGktv3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from captum.attr import IntegratedGradients\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w25tL4oh91rN"
      },
      "outputs": [],
      "source": [
        "# Example: take first correctly predicted suicide sample\n",
        "sample_ids = correct_suicide_samples[0].unsqueeze(0).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftEIAm139OcB"
      },
      "outputs": [],
      "source": [
        "\n",
        "baseline_ids = torch.full_like(sample_ids, model.config.pad_token_id).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSGHukLn96z7"
      },
      "outputs": [],
      "source": [
        "def get_embeddings(ids):\n",
        "    return model.bert.embeddings(\n",
        "        input_ids=ids,\n",
        "        token_type_ids=torch.zeros_like(ids)\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgEmnwXm-AS-"
      },
      "outputs": [],
      "source": [
        "input_embeddings = get_embeddings(sample_ids)\n",
        "baseline_embeddings = get_embeddings(baseline_ids)\n",
        "input_embeddings.requires_grad_(True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQrrXUC7-FQA"
      },
      "outputs": [],
      "source": [
        "from captum.attr import IntegratedGradients\n",
        "\n",
        "def forward_func(embeddings):\n",
        "    outputs = model.bert(\n",
        "        inputs_embeds=embeddings,\n",
        "        attention_mask=(sample_ids != model.config.pad_token_id).long()\n",
        "    )\n",
        "    cls_output = outputs.last_hidden_state[:, 0, :]\n",
        "    logits = model.classifier(cls_output)\n",
        "    return logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "reKy8Dup-IVi"
      },
      "outputs": [],
      "source": [
        "ig = IntegratedGradients(forward_func)\n",
        "\n",
        "# Target class: 1 for suicide\n",
        "attributions, delta = ig.attribute(\n",
        "    inputs=input_embeddings,\n",
        "    baselines=baseline_embeddings,\n",
        "    target=1,\n",
        "    return_convergence_delta=True\n",
        ")\n",
        "\n",
        "print(\"Attributions shape:\", attributions.shape)\n",
        "print(\"Convergence delta:\", delta.item())\n",
        "\n",
        "# Sum across embedding dimensions to get token-level importance\n",
        "token_importance = attributions.sum(dim=-1).squeeze(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UfKkLGbv-top"
      },
      "outputs": [],
      "source": [
        "tokens = tokenizer.convert_ids_to_tokens(sample_ids.squeeze(0))\n",
        "for token, score in zip(tokens, token_importance.cpu().detach().numpy()):\n",
        "    print(f\"{token}:  | |IGs|= {score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5mVH7bn_laP"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "from captum.attr import IntegratedGradients\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7GoaAadBSzg"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def visualize_token_heatmap(tokens, attributions, title=\"Token Attributions\"):\n",
        "    \"\"\"\n",
        "    Creates a heatmap where x-axis = tokens, y-axis = single row,\n",
        "    color = attribution score.\n",
        "    \"\"\"\n",
        "    # Convert to numpy and normalize\n",
        "    attr = attributions.cpu().detach().numpy()\n",
        "    attr_norm = (attr - attr.min()) / (attr.max() - attr.min() + 1e-8)\n",
        "\n",
        "    # Create figure\n",
        "    plt.figure(figsize=(min(len(tokens) * 0.5, 20), 2))\n",
        "    plt.imshow([attr_norm], cmap='RdYlGn', aspect='auto')\n",
        "    plt.colorbar(label=\"Attribution Strength\")\n",
        "\n",
        "    # Set x-ticks to tokens\n",
        "    plt.xticks(ticks=np.arange(len(tokens)), labels=[t.replace(\"##\", \"\") for t in tokens], rotation=45, ha='right')\n",
        "    plt.yticks([])  # hide y-axis\n",
        "    plt.title(title)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3N7HWjiAHrw"
      },
      "outputs": [],
      "source": [
        "def explain_correct_samples_heatmap(model, tokenizer, correct_samples, target_class=1, device=device, max_samples=5):\n",
        "    model.eval()\n",
        "\n",
        "    ig = IntegratedGradients(lambda x: model.classifier(model.bert(inputs_embeds=x).last_hidden_state[:,0,:]))\n",
        "\n",
        "    for idx, sample_ids in enumerate(correct_samples[:max_samples]):\n",
        "        sample_ids = sample_ids.unsqueeze(0).to(device)\n",
        "        baseline_ids = torch.full_like(sample_ids, model.config.pad_token_id).to(device)\n",
        "\n",
        "        # Get embeddings\n",
        "        input_embeddings = model.bert.embeddings(sample_ids)\n",
        "        baseline_embeddings = model.bert.embeddings(baseline_ids)\n",
        "        input_embeddings.requires_grad_(True)\n",
        "\n",
        "        # Compute attributions\n",
        "        attributions, delta = ig.attribute(\n",
        "            inputs=input_embeddings,\n",
        "            baselines=baseline_embeddings,\n",
        "            target=target_class,\n",
        "            return_convergence_delta=True\n",
        "        )\n",
        "\n",
        "        # Sum over embedding dimension\n",
        "        token_importance = attributions.sum(dim=-1).squeeze(0)\n",
        "\n",
        "        # Map tokens\n",
        "        tokens = tokenizer.convert_ids_to_tokens(sample_ids.squeeze(0))\n",
        "\n",
        "        # Visualize heatmap\n",
        "        visualize_token_heatmap(tokens, token_importance,\n",
        "                                title=f\"Sample {idx+1} - Convergence Delta: {delta.item():.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJdfgwpQAQva"
      },
      "outputs": [],
      "source": [
        "# Suicide samples\n",
        "#explain_correct_samples_heatmap(model, tokenizer, correct_suicide_samples, target_class=1, max_samples=3)\n",
        "\n",
        "# Non-suicide samples\n",
        "#explain_correct_samples_heatmap(model, tokenizer, correct_nonsuicide_samples, target_class=0, max_samples=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n27ih8l0CKuk"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "def visualize_token_heatmap_multiline(tokens, attributions, title=\"Token Attributions\", tokens_per_row=20):\n",
        "    \"\"\"\n",
        "    tokens: list of token strings\n",
        "    attributions: numpy array or torch tensor of token-level scores\n",
        "    tokens_per_row: number of tokens per row in heatmap\n",
        "    \"\"\"\n",
        "    # Convert to numpy and normalize\n",
        "    if torch.is_tensor(attributions):\n",
        "        attr = attributions.cpu().detach().numpy()\n",
        "    else:\n",
        "        attr = np.array(attributions)\n",
        "    attr_norm = (attr - attr.min()) / (attr.max() - attr.min() + 1e-8)\n",
        "\n",
        "    # Compute number of rows needed\n",
        "    num_tokens = len(tokens)\n",
        "    num_rows = math.ceil(num_tokens / tokens_per_row)\n",
        "\n",
        "    # Pad if necessary\n",
        "    pad_len = num_rows * tokens_per_row - num_tokens\n",
        "    attr_norm_padded = np.pad(attr_norm, (0, pad_len), 'constant', constant_values=np.nan)\n",
        "    tokens_padded = tokens + [''] * pad_len\n",
        "\n",
        "    # Reshape\n",
        "    attr_matrix = attr_norm_padded.reshape(num_rows, tokens_per_row)\n",
        "    token_matrix = np.array(tokens_padded).reshape(num_rows, tokens_per_row)\n",
        "\n",
        "    # Plot heatmap\n",
        "    plt.figure(figsize=(max(12, tokens_per_row * 0.5), max(2, num_rows * 0.5)))\n",
        "    im = plt.imshow(attr_matrix, cmap='RdYlGn', aspect='auto')\n",
        "    plt.colorbar(im, label=\"Attribution Strength\")\n",
        "\n",
        "    # Set ticks\n",
        "    for row_idx in range(num_rows):\n",
        "        for col_idx in range(tokens_per_row):\n",
        "            token = token_matrix[row_idx, col_idx].replace(\"##\", \"\")\n",
        "            if token != '':\n",
        "                plt.text(col_idx, row_idx, token, ha='center', va='center', fontsize=10)\n",
        "\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.title(title)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSrsSlgOCNhu"
      },
      "outputs": [],
      "source": [
        "def explain_correct_samples_multiline(model, tokenizer, correct_samples, target_class=1, device=device, max_samples=5, tokens_per_row=20):\n",
        "    model.eval()\n",
        "\n",
        "    ig = IntegratedGradients(lambda x: model.classifier(model.bert(inputs_embeds=x).last_hidden_state[:,0,:]))\n",
        "\n",
        "    for idx, sample_ids in enumerate(correct_samples[:max_samples]):\n",
        "        sample_ids = sample_ids.unsqueeze(0).to(device)\n",
        "        baseline_ids = torch.full_like(sample_ids, model.config.pad_token_id).to(device)\n",
        "\n",
        "        # Get embeddings\n",
        "        input_embeddings = model.bert.embeddings(sample_ids)\n",
        "        baseline_embeddings = model.bert.embeddings(baseline_ids)\n",
        "        input_embeddings.requires_grad_(True)\n",
        "\n",
        "        # Compute attributions\n",
        "        attributions, delta = ig.attribute(\n",
        "            inputs=input_embeddings,\n",
        "            baselines=baseline_embeddings,\n",
        "            target=target_class,\n",
        "            return_convergence_delta=True\n",
        "        )\n",
        "\n",
        "        # Sum over embedding dimension\n",
        "        token_importance = attributions.sum(dim=-1).squeeze(0)\n",
        "\n",
        "        # Map tokens\n",
        "        tokens = tokenizer.convert_ids_to_tokens(sample_ids.squeeze(0))\n",
        "\n",
        "        # Visualize heatmap\n",
        "        visualize_token_heatmap_multiline(tokens, token_importance,\n",
        "                                          title=f\"Sample {idx+1} - Convergence Delta: {delta.item():.4f}\",\n",
        "                                          tokens_per_row=tokens_per_row)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBCQw0yVCQTf"
      },
      "outputs": [],
      "source": [
        "# Suicide samples\n",
        "#explain_correct_samples_multiline(model, tokenizer, correct_suicide_samples, target_class=1, max_samples=3, tokens_per_row=20)\n",
        "\n",
        "# Non-suicide samples\n",
        "#explain_correct_samples_multiline(model, tokenizer, correct_nonsuicide_samples, target_class=0, max_samples=3, tokens_per_row=20)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukPDceZC2ExF"
      },
      "source": [
        "###“Integrated Gradients revealed salient semantic indicators such as abused, burden, and ending, which were not distinctly captured by attention visualisation. This highlights the limitation of attention weights as explanatory signals and supports the use of gradient-based attribution methods for reliable interpretability.”"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UmhmMKELGC3"
      },
      "outputs": [],
      "source": [
        "def merge_wordpieces(tokens, scores):\n",
        "    merged_tokens = []\n",
        "    merged_scores = []\n",
        "\n",
        "    current_word = \"\"\n",
        "    current_score = 0.0\n",
        "\n",
        "    for tok, score in zip(tokens, scores):\n",
        "        if tok in [\"[CLS]\", \"[SEP]\", \"[PAD]\"]:\n",
        "            continue\n",
        "\n",
        "        if tok.startswith(\"##\"):\n",
        "            current_word += tok[2:]\n",
        "            current_score += score\n",
        "        else:\n",
        "            if current_word:\n",
        "                merged_tokens.append(current_word)\n",
        "                merged_scores.append(current_score)\n",
        "            current_word = tok\n",
        "            current_score = score\n",
        "\n",
        "    if current_word:\n",
        "        merged_tokens.append(current_word)\n",
        "        merged_scores.append(current_score)\n",
        "\n",
        "    return merged_tokens, merged_scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIRkCyCAdlwe"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUIH9LFGLJUL"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "def collect_ig_scores(\n",
        "    model,\n",
        "    tokenizer,\n",
        "    correct_samples,\n",
        "    target_class,\n",
        "    max_samples=1000\n",
        "):\n",
        "    model.eval()\n",
        "\n",
        "    word_scores = defaultdict(float)\n",
        "    word_counts = defaultdict(int)\n",
        "\n",
        "    for sample_ids in correct_samples[:max_samples]:\n",
        "        sample_ids = sample_ids.unsqueeze(0).to(device)\n",
        "        baseline_ids = torch.full_like(\n",
        "            sample_ids, tokenizer.pad_token_id\n",
        "        ).to(device)\n",
        "\n",
        "        input_embeds = model.bert.embeddings(sample_ids)\n",
        "        baseline_embeds = model.bert.embeddings(baseline_ids)\n",
        "        input_embeds.requires_grad_(True)\n",
        "\n",
        "        ig = IntegratedGradients(\n",
        "            lambda x: model.classifier(\n",
        "                model.bert(inputs_embeds=x).last_hidden_state[:, 0, :]\n",
        "            )\n",
        "        )\n",
        "\n",
        "        attributions, delta = ig.attribute(\n",
        "            inputs=input_embeds,\n",
        "            baselines=baseline_embeds,\n",
        "            target=target_class,\n",
        "            return_convergence_delta=True\n",
        "        )\n",
        "\n",
        "        # Filter unreliable explanations\n",
        "        kept, skipped = 0, 0\n",
        "\n",
        "        if abs(delta.item()) <= 0.05:\n",
        "            kept += 1\n",
        "        else:\n",
        "            skipped += 1\n",
        "            continue\n",
        "\n",
        "\n",
        "        token_importance = attributions.sum(dim=-1).squeeze(0)\n",
        "        token_importance = token_importance / torch.norm(token_importance)\n",
        "\n",
        "        tokens = tokenizer.convert_ids_to_tokens(sample_ids.squeeze(0))\n",
        "        words, scores = merge_wordpieces(\n",
        "            tokens,\n",
        "            token_importance.detach().cpu().numpy()\n",
        "        )\n",
        "\n",
        "        for w, s in zip(words, scores):\n",
        "            w = w.lower()\n",
        "            if (\n",
        "                len(w) < 3 or\n",
        "                w in STOPWORDS or\n",
        "                not w.isalpha()\n",
        "            ):\n",
        "                continue\n",
        "\n",
        "            # IMPORTANT: only positive IG for suicide class\n",
        "            if s > 0:\n",
        "                word_scores[w] += s\n",
        "                word_counts[w] += 1\n",
        "\n",
        "    # Mean IG score per word\n",
        "    mean_word_scores = {\n",
        "        w: word_scores[w] / word_counts[w]\n",
        "        for w in word_scores\n",
        "        if word_counts[w] >= 2   # remove rare noise\n",
        "    }\n",
        "\n",
        "    return mean_word_scores\n",
        "    print(f\"IG kept: {kept}, skipped (high delta): {skipped}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oSv5XO-mLO9f"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "def plot_ig_wordcloud(\n",
        "    word_scores,\n",
        "    title,\n",
        "    filename,\n",
        "    save_dir=\"/content/drive/My Drive/Colab Notebooks/explainable_suicide_detection/bert_explainability_outputs\"\n",
        "):\n",
        "    wc = WordCloud(\n",
        "        width=1000,\n",
        "        height=400,\n",
        "        background_color=\"white\",\n",
        "        colormap=\"Reds\",\n",
        "        max_words=100\n",
        "    ).generate_from_frequencies(word_scores)\n",
        "\n",
        "    plt.figure(figsize=(14, 5))\n",
        "    plt.imshow(wc, interpolation=\"bilinear\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "     # ---- SAVE ----\n",
        "    import os\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    save_path = f\"{save_dir}/{filename}_{timestamp}.png\"\n",
        "    wc.to_file(save_path)\n",
        "\n",
        "    print(f\" WordCloud saved to: {save_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QRR02QYLWGJ"
      },
      "source": [
        "###Suicide Word Cloud (Label = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W85vCqpsLSxq"
      },
      "outputs": [],
      "source": [
        "suicide_word_scores = collect_ig_scores(\n",
        "    model,\n",
        "    tokenizer,\n",
        "    correct_suicide_samples,\n",
        "    target_class=1,\n",
        "    max_samples=1000\n",
        ")\n",
        "\n",
        "plot_ig_wordcloud(\n",
        "    suicide_word_scores,\n",
        "    title=\"IG-Weighted Word Cloud — Suicide Class\",\n",
        "    filename=\"ig_BERT_wordcloud_suicide\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NyKP9k8LZJa"
      },
      "source": [
        "###Non-Suicide Word Cloud (Label = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vB5VgeBCLdPI"
      },
      "outputs": [],
      "source": [
        "nonsuicide_word_scores = collect_ig_scores(\n",
        "    model,\n",
        "    tokenizer,\n",
        "    correct_nonsuicide_samples,\n",
        "    target_class=0,\n",
        "    max_samples=1000\n",
        ")\n",
        "\n",
        "plot_ig_wordcloud(\n",
        "    nonsuicide_word_scores,\n",
        "    title=\"IG-Weighted Word Cloud — Non-Suicide Class\",\n",
        "    filename=\"ig_BERT_wordcloud_nonsuicide\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4ja_Xe7Ls8V"
      },
      "source": [
        "#####We further aggregated Integrated Gradient attributions across correctly predicted samples to construct IG-weighted word clouds, revealing class-specific semantic cues driving model predictions.”\n",
        "#####While attention weights were analysed to provide structural insight into model focus, we observed that attention often concentrated on special tokens. Integrated Gradients, in contrast, produced sparse and semantically meaningful attributions. We therefore use attention as a complementary diagnostic signal, and IG as the primary explanation method.”"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rq8lTosNQTgr"
      },
      "source": [
        "#####While prior work primarily relied on SHAP-based explanations, our findings indicate that embedding-based Integrated Gradients provide comparable faithfulness with substantially lower computational cost and clearer token-level attributions in Transformer-based suicide risk detection.”"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mB1fzQMYQTdP"
      },
      "source": [
        "####Interestingly, intent-weighted Integrated Gradients emphasized latent affective and cognitive markers (e.g., ‘hopeless’, ‘alone’, ‘tired’) over explicit suicide-related terms. This suggests that the model captures underlying psychological distress rather than relying on keyword presence, aligning with clinical findings that suicidal ideation is often communicated implicitly.”"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REUhzQNjQTGu"
      },
      "source": [
        "#CONTRASTIVE INTEGRATED GRADIENTS (Suicide − Non-Suicide)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feEmSFtCvNTX"
      },
      "source": [
        "####IGcontrast​(w)=IGsuicide​(w)−IGnon_suicide​(w)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5eHU1VMvIqV"
      },
      "outputs": [],
      "source": [
        "from captum.attr import IntegratedGradients\n",
        "from collections import defaultdict\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def collect_ig_scores(\n",
        "    model,\n",
        "    tokenizer,\n",
        "    correct_samples,\n",
        "    target_class,\n",
        "    max_samples=1000,\n",
        "    device='cuda'\n",
        "):\n",
        "    model.eval()\n",
        "    ig = IntegratedGradients(\n",
        "        lambda x: model.classifier(\n",
        "            model.bert(inputs_embeds=x).last_hidden_state[:, 0, :]\n",
        "        )\n",
        "    )\n",
        "\n",
        "    word_scores = defaultdict(float)\n",
        "    word_counts = defaultdict(int)\n",
        "\n",
        "    for sample_ids in correct_samples[:max_samples]:\n",
        "        sample_ids = sample_ids.unsqueeze(0).to(device)\n",
        "\n",
        "        baseline_ids = torch.full_like(\n",
        "            sample_ids,\n",
        "            tokenizer.pad_token_id\n",
        "        ).to(device)\n",
        "\n",
        "        input_embeds = model.bert.embeddings(sample_ids)\n",
        "        baseline_embeds = model.bert.embeddings(baseline_ids)\n",
        "        input_embeds.requires_grad_(True)\n",
        "\n",
        "        attributions = ig.attribute(\n",
        "            inputs=input_embeds,\n",
        "            baselines=baseline_embeds,\n",
        "            target=target_class\n",
        "        )\n",
        "\n",
        "        token_scores = attributions.sum(dim=-1).squeeze(0).detach().cpu().numpy()\n",
        "        tokens = tokenizer.convert_ids_to_tokens(sample_ids.squeeze(0))\n",
        "\n",
        "        for tok, score in zip(tokens, token_scores):\n",
        "            if tok not in [\"[CLS]\", \"[SEP]\", \"[PAD]\"]:\n",
        "                tok = tok.replace(\"##\", \"\")\n",
        "                word_scores[tok] += score\n",
        "                word_counts[tok] += 1\n",
        "\n",
        "    # Average attribution per word\n",
        "    #for w in word_scores:\n",
        "     #   word_scores[w] /= (word_counts[w] + 1e-8)\n",
        "\n",
        "    #return dict(word_scores)\n",
        "\n",
        "    # Average IG per word\n",
        "    avg_word_scores = {\n",
        "        w: word_scores[w] / (word_counts[w] + 1e-8)\n",
        "        for w in word_scores\n",
        "    }\n",
        "\n",
        "    return avg_word_scores\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxlqsftNvu76"
      },
      "source": [
        "###COMPUTE CONTRASTIVE IG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1qWMAGiPPML"
      },
      "outputs": [],
      "source": [
        "suicide_ig = collect_ig_scores(\n",
        "    model,\n",
        "    tokenizer,\n",
        "    correct_suicide_samples,\n",
        "    target_class=1,\n",
        "    max_samples=200\n",
        ")\n",
        "\n",
        "nonsuicide_ig = collect_ig_scores(\n",
        "    model,\n",
        "    tokenizer,\n",
        "    correct_nonsuicide_samples,\n",
        "    target_class=0,\n",
        "    max_samples=200\n",
        ")\n",
        "\n",
        "# Contrastive IG\n",
        "contrastive_ig = {}\n",
        "\n",
        "for word in suicide_ig:\n",
        "    contrastive_ig[word] = suicide_ig[word] - nonsuicide_ig.get(word, 0.0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4XmoLwov6rV"
      },
      "source": [
        "###Keep Only Strong Suicide-Specific Signals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EkWGw5W5v50i"
      },
      "outputs": [],
      "source": [
        "contrastive_ig = {\n",
        "    w: v for w, v in contrastive_ig.items()\n",
        "    if v > 0\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yFpzy3zwCyV"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "wc = WordCloud(\n",
        "    width=1400,\n",
        "    height=500,\n",
        "    background_color=\"white\",\n",
        "    colormap=\"Reds\"\n",
        ").generate_from_frequencies(contrastive_ig)\n",
        "\n",
        "plot_ig_wordcloud(\n",
        "    contrastive_ig,\n",
        "    title=\"Contrastive Integrated Gradients (Suicide − Non-Suicide) — BERT\",\n",
        "    filename=\"BERT_contrastive_suicide_nonsuicide\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zO0Lb5uIQIf"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "huJYYycSIPsp"
      },
      "outputs": [],
      "source": [
        "top_20_ig = sorted(\n",
        "    suicide_ig.items(),\n",
        "    key=lambda x: x[1],\n",
        "    reverse=True\n",
        ")[:20]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jI6S8n2_IUhr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_top20_ig = pd.DataFrame(\n",
        "    top_20_ig,\n",
        "    columns=[\"Word\", \"Avg IG Score\"]\n",
        ")\n",
        "\n",
        "df_top20_ig\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCgzMn-yIYv6"
      },
      "outputs": [],
      "source": [
        "df_top20_ig[\"Avg IG Score\"] = df_top20_ig[\"Avg IG Score\"].round(4)\n",
        "df_top20_ig\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VimVixS9Ib3T"
      },
      "outputs": [],
      "source": [
        "df_top20_ig.to_csv(\"top20_ig_suicide_words.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Cs3ppWFIhUv"
      },
      "source": [
        "####Table X reports the top 20 tokens ranked by average Integrated Gradients attribution for the suicide class. Notably, the model assigns higher importance to latent affective expressions (e.g., ‘hopeless’, ‘alone’, ‘done’) rather than explicit suicide-related terms, indicating reliance on underlying psychological distress cues.”"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAnSd3Zo4cOb"
      },
      "source": [
        "#ATTENTION × INTEGRATED GRADIENTS (FUSION)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}